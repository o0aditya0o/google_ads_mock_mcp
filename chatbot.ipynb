{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51796a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%pip install -U arxiv dotenv google google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e79a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc6e99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "747cacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int= 5) -> List[str]:\n",
    "  \"\"\"\n",
    "  Search for papers on arXiv based on a topic and store their information.\n",
    "\n",
    "  Args:\n",
    "    topic: The topic to search for\n",
    "    max_results : Maximum number of results to retrieve(default:5)\n",
    "\n",
    "    Returns:\n",
    "      List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "\n",
    "  #Use arxiv to find the papers\n",
    "  client = arxiv.Client()\n",
    "\n",
    "  #Search for the most relevant articles matching the queried topic\n",
    "  search = arxiv.Search(\n",
    "      query = topic,\n",
    "      max_results = max_results,\n",
    "      sort_by = arxiv.SortCriterion.Relevance\n",
    "  )\n",
    "\n",
    "  papers = client.results(search)\n",
    "\n",
    "  #Create directory for this topic\n",
    "  path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "  os.makedirs(path, exist_ok=True)\n",
    "\n",
    "  file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "  #Try to load existing papers info\n",
    "  try:\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "      papers_info = json.load(json_file)\n",
    "  except (FileNotFoundError, json.JSONDecodeError):\n",
    "    papers_info = {}\n",
    "\n",
    "  #Process each paper and add to papers_info\n",
    "  paper_ids = []\n",
    "  for paper in papers:\n",
    "    paper_ids.append(paper.get_short_id())\n",
    "    paper_info = {\n",
    "        'title': paper.title,\n",
    "        'authors': [author.name for author in paper.authors],\n",
    "        'summary': paper.summary,\n",
    "        'pdf_url': paper.pdf_url,\n",
    "        'published': str(paper.published.date())\n",
    "    }\n",
    "    papers_info[paper.get_short_id()] = paper_info\n",
    "\n",
    "  #Save updated papers_info to json file\n",
    "  with open(file_path, \"w\") as json_file:\n",
    "    json.dump(papers_info, json_file, indent=2)\n",
    "\n",
    "  print(f\"Results are saved in: {file_path}\")\n",
    "\n",
    "  return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42819db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers/alphaevolve/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2505.16105v1', '2103.16196v2']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"alphaevolve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca051287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "  \"\"\"\n",
    "  Search for information about a specific paper across all topic directories.\n",
    "\n",
    "  Args:\n",
    "    paper_id: The ID of the paper to look for\n",
    "\n",
    "  Returns:\n",
    "    JSON string with paper information if found, error message if not found\n",
    "  \"\"\"\n",
    "\n",
    "  print(os.listdir(PAPER_DIR))\n",
    "  for item in os.listdir(PAPER_DIR):\n",
    "    item_path = os.path.join(PAPER_DIR, item)\n",
    "    if os.path.isdir(item_path):\n",
    "      file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "      if os.path.isfile(file_path):\n",
    "        try:\n",
    "          with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "            if paper_id in papers_info:\n",
    "              return json.dumps(papers_info[paper_id], indent=2)\n",
    "        except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "          print(f\"Error reading {file_path}: {str(e)}\")\n",
    "          continue\n",
    "\n",
    "  return f\"There is no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "257ffede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llm', 'alphaevolve']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Sums and differences of sets (improvement over AlphaEvolve)\",\\n  \"authors\": [\\n    \"Robert Gerbicz\"\\n  ],\\n  \"summary\": \"On May 14, 2025, DeepMind announced that AlphaEvolve, a large language model\\\\napplied to a set of mathematical problems, had matched or exceeded the best\\\\nknown bounds on several problems. In the case of the sum and difference of sets\\\\nproblem, AlphaEvolve, using a set of $54265$ integers, improved the known lower\\\\nbound of $\\\\\\\\theta=1.14465$ to $\\\\\\\\theta=1.1584$. In this paper, we present an\\\\nimproved bound $\\\\\\\\theta=1.173050$ using an explicit construction of a U set that\\\\ncontains more than $10^{43546}$ elements. For fast integer and floating-point\\\\narithmetic, we used the (free) GMP library.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/2505.16105v1\",\\n  \"published\": \"2025-05-22\"\\n}'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info('2505.16105v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39d22b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ~/.zshrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d05c7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Configure your API key\n",
    "import json\n",
    "\n",
    "# Load config\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "api_key = config['api_key']\n",
    "genai.configure(api_key=api_key) # Replace with your actual API key\n",
    "\n",
    "from google.generativeai.protos import FunctionDeclaration, Tool, Schema, Type\n",
    "tools = [\n",
    "    Tool(\n",
    "        function_declarations=[\n",
    "            FunctionDeclaration(\n",
    "                name=\"search_papers\",\n",
    "                description=\"Search for papers on arXiv based on a topic and store their information.\",\n",
    "                parameters=Schema(\n",
    "                    type=Type.OBJECT,\n",
    "                    properties={\n",
    "                        \"topic\": Schema(\n",
    "                            type=Type.STRING,\n",
    "                            description=\"The topic to search for\"\n",
    "                        ),\n",
    "                        \"max_results\": Schema(\n",
    "                            type=Type.INTEGER,\n",
    "                            description=\"Maximum number of results to retrieve\",\n",
    "                            # default=5\n",
    "                        )\n",
    "                    },\n",
    "                    required=[\"topic\"]\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    Tool(\n",
    "        function_declarations=[\n",
    "            FunctionDeclaration(\n",
    "                name=\"extract_info\",\n",
    "                description=\"Search for information about a specific paper across all topic directories.\",\n",
    "                parameters=Schema(\n",
    "                    type=Type.OBJECT,\n",
    "                    properties={\n",
    "                        \"paper_id\": Schema(\n",
    "                            type=Type.STRING,\n",
    "                            description=\"The ID of the paper to look for\"\n",
    "                        )\n",
    "                    },\n",
    "                    required=[\"paper_id\"]\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "def process_query(query):\n",
    "\n",
    "  #Define the Gemini model\n",
    "  model = genai.GenerativeModel('gemini-2.5-flash-preview-05-20', tools=tools)\n",
    "\n",
    "  #Start a chat session\n",
    "  chat_session = model.start_chat(history=[])\n",
    "\n",
    "  #Send the user query\n",
    "  response = chat_session.send_message(query)\n",
    "\n",
    "  # print(f\"Intial responses from chatbot: {response}\")\n",
    "\n",
    "  process_query=True\n",
    "  while process_query:\n",
    "    assistant_content = []\n",
    "    tool_calls_made = False\n",
    "\n",
    "    #Process the response\n",
    "    for part in response.candidates[0].content.parts:\n",
    "      if part.text:\n",
    "        print(part.text)\n",
    "        assistant_content.append({\"text\": part.text})\n",
    "        if len(response.candidates[0].content.parts) == 1 and not part.function_call:\n",
    "          process_query = False\n",
    "\n",
    "      if part.function_call:\n",
    "        tool_calls_made = True\n",
    "        tool_name = part.function_call.name\n",
    "        tool_args = part.function_call.args\n",
    "\n",
    "        print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "\n",
    "        #Execute tool\n",
    "        result = execute_tool(tool_name, tool_args)\n",
    "\n",
    "        #Send the tool result back to the model\n",
    "        response = chat_session.send_message(genai.protos.Content(\n",
    "            parts=[genai.protos.Part(\n",
    "                function_response=genai.protos.FunctionResponse(\n",
    "                    name=tool_name,\n",
    "                    response={'content': result}\n",
    "                )\n",
    "            )]\n",
    "        ))\n",
    "\n",
    "      if not tool_calls_made and len(response.candidates[0].content.parts) == 1 and response.candidates[0].content.parts[0].text:\n",
    "            process_query = False\n",
    "\n",
    "      if tool_calls_made and not response.candidates[0].content.parts[0].text and not response.candidates[0].content.parts[0].function_call:\n",
    "             process_query = False\n",
    "\n",
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "\n",
    "  result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "  if result is None:\n",
    "      result = \"The operation completed but didn't return any results.\"\n",
    "\n",
    "  elif isinstance(result, list):\n",
    "      result = ', '.join(result)\n",
    "\n",
    "  elif isinstance(result, dict):\n",
    "      # Convert dictionaries to formatted JSON strings\n",
    "      result = json.dumps(result, indent=2)\n",
    "\n",
    "  else:\n",
    "      # For any other type, convert using str()\n",
    "      result = str(result)\n",
    "  return result\n",
    "\n",
    "# Example usage:\n",
    "# process_query_gemini(\"Find me 3 recent papers on large language models.\", tools, execute_tool)\n",
    "# process_query_gemini(\"Extract information for paper ID 2305.01234.\", tools, execute_tool)\n",
    "# process_query_gemini(\"Tell me a simple joke.\", tools, execute_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c079273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "  print(\"Type your queries or 'quit' to exit.\")\n",
    "  while True:\n",
    "    try:\n",
    "      query = input(\"\\nQuery: \").strip()\n",
    "      if query.lower() == 'quit':\n",
    "        break\n",
    "\n",
    "      process_query(query)\n",
    "      print(\"\\n\")\n",
    "    except Exception as e:\n",
    "      print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0590d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n",
      "Hello! I'm a bot that can help you with your academic research. I can search for papers on arXiv and extract information about them. What would you like to do?\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e880a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
